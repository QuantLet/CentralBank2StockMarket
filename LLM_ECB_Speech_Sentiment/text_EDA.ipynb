{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503caa28-2cd1-48f3-867f-ef0c1f505fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.util import ngrams\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ace860-c2c7-451d-8b37-56f43d1838e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6d88dd-5c56-483e-a9a3-4c21eadae8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2ac4c0-bd9a-4f3c-b89e-25951d7a3973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spaCy model for Named Entity Recognition (NER)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def text_eda(text):\n",
    "    \"\"\"Performs exploratory data analysis on a given text.\"\"\"\n",
    "    \n",
    "    # Tokenization\n",
    "    words = word_tokenize(text.lower())\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    # Remove punctuation and stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word.isalnum() and word not in stop_words]\n",
    "    \n",
    "    # Basic statistics\n",
    "    total_words = len(words)\n",
    "    total_sentences = len(sentences)\n",
    "    avg_word_length = sum(len(word) for word in words) / total_words\n",
    "    \n",
    "    print(f\"Total Words: {total_words}\")\n",
    "    print(f\"Total Sentences: {total_sentences}\")\n",
    "    print(f\"Average Word Length: {avg_word_length:.2f}\")\n",
    "    \n",
    "    # Word Frequency Distribution\n",
    "    word_freq = Counter(words)\n",
    "    common_words = word_freq.most_common(20)\n",
    "    print(\"\\nMost Common Words:\")\n",
    "    for word, freq in common_words:\n",
    "        print(f\"{word}: {freq}\")\n",
    "    \n",
    "    # Plot Word Frequency\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(*zip(*common_words))\n",
    "    plt.xlabel(\"Words\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.xticks(rotation=90, ha='right')\n",
    "    plt.title(\"Top 10 Most Common Words\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Generate Word Cloud\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(words))\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Word Cloud\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Bigram Analysis\n",
    "    bigrams = list(ngrams(words, 2))\n",
    "    bigram_freq = Counter(bigrams).most_common(5)\n",
    "    print(\"\\nMost Common Bigrams:\")\n",
    "    for bigram, freq in bigram_freq:\n",
    "        print(f\"{' '.join(bigram)}: {freq}\")\n",
    "    \n",
    "    # # Named Entity Recognition (NER)\n",
    "    # doc = nlp(text)\n",
    "    # print(\"\\nNamed Entities:\")\n",
    "    # for ent in doc.ents:\n",
    "    #     print(f\"{ent.text} ({ent.label_})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad09cf55-f1e4-4467-b759-bd1ff5d5b774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('all_ECB_speeches_para.csv')\n",
    "\n",
    "# text_eda(sample_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dc5a8e-64e7-44de-a60c-db3f3fbc93cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = ''\n",
    "for i in df['contents_para']:\n",
    "    if isinstance(i, str):\n",
    "        text += (i + ' ')\n",
    "    else:\n",
    "        None\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f73784b-dab1-472a-abd1-18410c547c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.max_length = 54723303  # Increase the maximum character limit for spaCy\n",
    "text_eda(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd61ff03-adae-4c8d-8b76-29b5fc1a6712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e8294c-ea63-4664-8500-0d87fb63b4b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b978e4d-c943-486d-a91d-819ce58bb775",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:RT_PythonEnv_LLM_DRL]",
   "language": "python",
   "name": "conda-env-RT_PythonEnv_LLM_DRL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
